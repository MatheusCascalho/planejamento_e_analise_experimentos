binom.test(50, 100, p=0, alternative = "greater")
%% aa
pwrss.z.prop
nstall.packages("pwrss")
install.packages("pwrss")
help pwrss.z.prop
pwrss.z.prop
pwrss.z.prop?
?
!
dfsdfs
pwrss.z.prop??
c
pwrss.z.prop??
power
help(pwrss.z.prop)
??pwrss.z.prop
# Descobrindo o número de amostras para serem testadas na telemont
library(pwrss)
# Nos erros, a proporção Enel parece ser de 55%. Para sermos conservadores
# colocamos 40%.
# A proporção deveria ser 0
success_number <- 0.4
expected_proportion <- 0
# Desejamos evitar fortemente falsos negativos (Erro tipo 2)
# Desejamos ter 99% de certeza do nosso teste
statistical_power <- 0.95
alpha <- 0.01
pwrss.z.prop(p = success_number, p0 = expected_proportion,
alpha = alpha, power = statistical_power,
alternative = "more")
# Descobrindo o número de amostras para serem testadas na telemont
library(pwrss)
# Nos erros, a proporção Enel parece ser de 55%. Para sermos conservadores
# colocamos 40%.
# A proporção deveria ser 0
success_number <- 0.4
expected_proportion <- 0
# Desejamos evitar fortemente falsos negativos (Erro tipo 2)
# Desejamos ter 99% de certeza do nosso teste
statistical_power <- 0.95
alpha <- 0.01
pwrss.z.prop(p = success_number, p0 = expected_proportion,
alpha = alpha, power = statistical_power,
alternative = "greater")
# binom.test(50, 100, p=0, alternative = "greater")
# Descobrindo o número de amostras para serem testadas na telemont
library(pwrss)
# Nos erros, a proporção Enel parece ser de 55%. Para sermos conservadores
# colocamos 40%.
# A proporção deveria ser 0
success_number <- 0.4
expected_proportion <- 0
# Desejamos evitar fortemente falsos negativos (Erro tipo 2)
# Desejamos ter 99% de certeza do nosso teste
statistical_power <- 0.95
alpha <- 0.01
pwrss.z.prop(p = success_number, p0 = expected_proportion,
alpha = alpha, power = statistical_power,
alternative = "greater")
# Teste Real de Hipótese
# Teste binomial
enel_errors <- 50
sample_size <- 100
binom.test(enel_errors, sample_size, p=0, alternative = "greater")
# Descobrindo o número de amostras para serem testadas na telemont
library(pwrss)
# Nos erros, a proporção Enel parece ser de 55%. Para sermos conservadores
# colocamos 40%.
# A proporção deveria ser 0
success_number <- 0.4
expected_proportion <- 0
# Desejamos evitar fortemente falsos negativos (Erro tipo 2)
# Desejamos ter 99% de certeza do nosso teste
statistical_power <- 0.95
alpha <- 0.01
pwrss.z.prop(p = success_number, p0 = expected_proportion,
alpha = alpha, power = statistical_power,
alternative = "greater", n=10000)
# Descobrindo o número de amostras para serem testadas na telemont
library(pwrss)
# Nos erros, a proporção Enel parece ser de 55%. Para sermos conservadores
# colocamos 40%.
# A proporção deveria ser 0
success_number <- 0.4
expected_proportion <- 0
# Desejamos evitar fortemente falsos negativos (Erro tipo 2)
# Desejamos ter 99% de certeza do nosso teste
statistical_power <- 0.95
alpha <- 0.01
pwrss.z.prop(p = success_number, p0 = expected_proportion,
alpha = alpha, power = statistical_power,
alternative = "greater")
# Teste Real de Hipótese
# Teste binomial
enel_errors <- 50
sample_size <- 100
binom.test(enel_errors, sample_size, p=0, alternative = "greater")
# Descobrindo o número de amostras para serem testadas na telemont
library(pwrss)
# Nos erros, a proporção Enel parece ser de 55%. Para sermos conservadores
# colocamos 40%.
# A proporção deveria ser 0
success_number <- 0.4
expected_proportion <- 0
# Desejamos evitar fortemente falsos negativos (Erro tipo 2)
# Desejamos ter 99% de certeza do nosso teste
statistical_power <- 0.95
alpha <- 0.01
pwrss.z.prop(p = success_number, p0 = expected_proportion,
alpha = alpha, power = statistical_power,
alternative = "greater")
# Teste Real de Hipótese
# Teste binomial
enel_errors <- 10
sample_size <- 24
binom.test(enel_errors, sample_size, p=0, alternative = "greater")
# Descobrindo o número de amostras para serem testadas na telemont
library(pwrss)
# Nos erros, a proporção Enel parece ser de 55%. Para sermos conservadores
# colocamos 40%.
# A proporção deveria ser 0
success_number <- 0.4
expected_proportion <- 0
# Desejamos evitar fortemente falsos negativos (Erro tipo 2)
# Desejamos ter 99% de certeza do nosso teste
statistical_power <- 0.975
alpha <- 0.01
pwrss.z.prop(p = success_number, p0 = expected_proportion,
alpha = alpha, power = statistical_power,
alternative = "greater")
# Teste Real de Hipótese
# Teste binomial
enel_errors <- 10
sample_size <- 24
binom.test(enel_errors, sample_size, p=0, alternative = "greater")
enel_errors <- 15
sample_size <- 30
binom.test(enel_errors, sample_size, p=0, alternative = "greater")
enel_errors <- 60
sample_size <- 100
binom.test(enel_errors, sample_size, p=0, alternative = "greater")
# Descobrindo o número de amostras para serem testadas na telemont
library(pwrss)
# Nos erros, a proporção Enel parece ser de 55%. Para sermos conservadores
# colocamos 40%.
# A proporção deveria ser 0
success_number <- 0.4
expected_proportion <- 0
# Desejamos evitar fortemente falsos negativos (Erro tipo 2)
# Desejamos ter 99% de certeza do nosso teste
statistical_power <- 0.975
alpha <- 0.01
pwrss.z.prop(p = success_number, p0 = expected_proportion,
alpha = alpha, power = statistical_power,
alternative = "greater")
# Teste Real de Hipótese
# Teste binomial
enel_errors <- 60
sample_size <- 100
binom.test(enel_errors, sample_size, p=0, alternative = "greater")
imc2016 <- read.csv('imc_20162.csv')
imc2017 <- read.csv('CS01_20172.csv', sep = ';')
load("~/Documents/planejamento-analise-experimentos/planejamento_e_analise_experimentos/case_study_01.Rmd")
load("~/Documents/planejamento-analise-experimentos/planejamento_e_analise_experimentos/CS01_20172.csv")
imc2016 <- read.csv('./imc_20162.csv')
setwd("/Users/henriquealvesbarbosa/Documents/planejamento-analise-experimentos/planejamento_e_analise_experimentos")
imc2016 <- read.csv('imc_20162.csv')
imc2017 <- read.csv('CS01_20172.csv', sep = ';')
# Carregamento de dados
setwd("/Users/henriquealvesbarbosa/Documents/planejamento-analise-experimentos/planejamento_e_analise_experimentos")
imc2016 <- read.csv('imc_20162.csv')
imc2017 <- read.csv('CS01_20172.csv', sep = ';')
# Filtragem de dados
imc2016 <- imc2016[imc2016$Course == 'PPGEE',]
# Padronização do dataframe
colnames(imc2016)[colnames(imc2016)=='Gender'] <- 'Sex'
colnames(imc2016)[colnames(imc2016)=='Height.m'] <- 'height.m'
colnames(imc2016)[colnames(imc2016)=='Weight.kg'] <- 'weight.kg'
colnames(imc2017)[colnames(imc2017)=='Weight.kg'] <- 'weight.kg'
imc2016 = imc2016[,c('Sex', 'height.m', 'weight.kg')]
imc2017 = imc2017[,c('Sex', 'height.m', 'weight.kg')]
imc2016$amostra <- '2016'
imc2017$amostra <- '2017'
# Calculando o IMC de cada população
imc2016$imc <- imc2016$weight.kg/(imc2016$height.m^2)
imc2017$imc <- imc2017$weight.kg/(imc2017$height.m^2)
# Normalização das amostras
n1 = length(imc2016$imc)
sigma_1 = sd(imc2016$imc)
mu_1 = mean(imc2016$imc)
imc2016$z0 <- (imc2016$imc - mu_1)/(sigma_1/sqrt(n1))
n2 = length(imc2017$imc)
sigma_2 = sd(imc2017$imc)
mu_2 = mean(imc2017$imc)
imc2017$z0 <- (imc2017$imc - mu_2)/(sigma_2/sqrt(n2))
imc <- rbind(imc2016, imc2017)
# Segregação de dados entre Homens e Mulheres
imc_feminino <- imc[imc$Sex == 'F',]
imc_masculino <- imc[imc$Sex == 'M',]
#hist(imc$imc, col = 'grey')
#hist(imc_masculino$imc, col = 'lightblue', probability=TRUE)
#hist(imc_feminino$imc, col = 'red', probability=TRUE, add = TRUE)
# Teste de hipótese
## - Teste de hipótese entre imc homens e mulheres da pós (supõe iid)
# IID(Independente e Igualmente distribuida): significa que temos uma amostra representativa da população total
# Vamos supor que o IMC de homens é igual ao de mulheres
# H0: mu_m = mu_h
# H1: mu_m < mu_h
# Teste unilateral. Podemos assumir isso pois acreditamos que o IMC das mulheres será menor que o dos homens
# Premissa: amostrar com a mesma variância
fligner.test(imc ~ Sex, data = imc) # H0: VARIANCIAS IGUAIS
# Resulto do teste de fligner < 0.05 -> podemos assumir variancias iguais
# Premissa: amostras seguem a normalidade
# H0: Distribuição é normal
# Resulto do teste de shapiro < 0.05 -> podemos assumir normalidade
shapiro.test(imc$imc[imc$Sex == "F"]) # p-value = 0.3179 -> aceitamos H0
power.t.test(delta       = mean(imc_feminino$imc)*0.1,
sd          = sd(imc_feminino$imc),
sig.level   = 0.05,
# power       = 0.8,
n = 11,
type        = "one.sample",
alternative = "one.sided")
shapiro.test(imc$imc[imc$Sex == "M"]) # p-value = 0.0618 -> rejeitamos H0, não segue normalidade (por muito pouco)
power.t.test(delta       = mean(imc_masculino$imc)*0.1,
sd          = sd(imc_masculino$imc),
sig.level   = 0.05,
# power       = 0.8,
n = 42,
type        = "one.sample",
alternative = "one.sided")
t.test(imc$imc ~ imc$Sex,
alternative = "less",
mu          = 0,
var.equal   = TRUE,
conf.level  = 0.95)
# p-value = 0.0003175 -> rejeitamos H0, ou seja, o IMC das populações é diferente.
# H1: mu_m < mu_h
# Resulto do hipotese < 0.05 -> podemos rejeitar H0
power.t.test(delta       = mean(imc$imc)*0.1,
sd          = sd(imc$imc),
sig.level   = 0.05,
# power       = 0.8,
n = length(imc$imc),
type        = "two.sample",
alternative = "one.sided")
# power = 0.911528
library(confintr) # package for confidence intervals
library(ggplot2)
ci_masculino = ci_mean(imc_masculino$imc, probs = c(0.05, 0.95),
type = c("t"))
ci_feminino = ci_mean(imc_feminino$imc, probs = c(0.05, 0.95),
type = c("t"))
for (i in 1:N) {
# generate normally distributed sample of size n
rsample <- rnorm(n, mean = 50, sd = 5)
# calculate confidence interval
ci = ci_mean(rsample, probs = c(0.025, 0.975),
type = c("t"))
mean[i] <- ci$estimate
L[i] <- ci$interval[1]
U[i] <- ci$interval[2]
}
# Carregamento de dados
setwd("/Users/henriquealvesbarbosa/Documents/planejamento-analise-experimentos/planejamento_e_analise_experimentos")
imc2016 <- read.csv('imc_20162.csv')
imc2017 <- read.csv('CS01_20172.csv', sep = ';')
# Filtragem de dados
imc2016 <- imc2016[imc2016$Course == 'PPGEE',]
# Padronização do dataframe
colnames(imc2016)[colnames(imc2016)=='Gender'] <- 'Sex'
colnames(imc2016)[colnames(imc2016)=='Height.m'] <- 'height.m'
colnames(imc2016)[colnames(imc2016)=='Weight.kg'] <- 'weight.kg'
colnames(imc2017)[colnames(imc2017)=='Weight.kg'] <- 'weight.kg'
imc2016 = imc2016[,c('Sex', 'height.m', 'weight.kg')]
imc2017 = imc2017[,c('Sex', 'height.m', 'weight.kg')]
imc2016$amostra <- '2016'
imc2017$amostra <- '2017'
# Calculando o IMC de cada população
imc2016$imc <- imc2016$weight.kg/(imc2016$height.m^2)
imc2017$imc <- imc2017$weight.kg/(imc2017$height.m^2)
# Normalização das amostras
n1 = length(imc2016$imc)
sigma_1 = sd(imc2016$imc)
mu_1 = mean(imc2016$imc)
imc2016$z0 <- (imc2016$imc - mu_1)/(sigma_1/sqrt(n1))
n2 = length(imc2017$imc)
sigma_2 = sd(imc2017$imc)
mu_2 = mean(imc2017$imc)
imc2017$z0 <- (imc2017$imc - mu_2)/(sigma_2/sqrt(n2))
imc <- rbind(imc2016, imc2017)
# Segregação de dados entre Homens e Mulheres
imc_feminino <- imc[imc$Sex == 'F',]
imc_masculino <- imc[imc$Sex == 'M',]
#hist(imc$imc, col = 'grey')
#hist(imc_masculino$imc, col = 'lightblue', probability=TRUE)
#hist(imc_feminino$imc, col = 'red', probability=TRUE, add = TRUE)
# Teste de hipótese
## - Teste de hipótese entre imc homens e mulheres da pós (supõe iid)
# IID(Independente e Igualmente distribuida): significa que temos uma amostra representativa da população total
# Vamos supor que o IMC de homens é igual ao de mulheres
# H0: mu_m = mu_h
# H1: mu_m < mu_h
# Teste unilateral. Podemos assumir isso pois acreditamos que o IMC das mulheres será menor que o dos homens
# Premissa: amostrar com a mesma variância
fligner.test(imc ~ Sex, data = imc) # H0: VARIANCIAS IGUAIS
# Resulto do teste de fligner < 0.05 -> podemos assumir variancias iguais
# Premissa: amostras seguem a normalidade
# H0: Distribuição é normal
# Resulto do teste de shapiro < 0.05 -> podemos assumir normalidade
shapiro.test(imc$imc[imc$Sex == "F"]) # p-value = 0.3179 -> aceitamos H0
power.t.test(delta       = mean(imc_feminino$imc)*0.1,
sd          = sd(imc_feminino$imc),
sig.level   = 0.05,
# power       = 0.8,
n = 11,
type        = "one.sample",
alternative = "one.sided")
shapiro.test(imc$imc[imc$Sex == "M"]) # p-value = 0.0618 -> rejeitamos H0, não segue normalidade (por muito pouco)
power.t.test(delta       = mean(imc_masculino$imc)*0.1,
sd          = sd(imc_masculino$imc),
sig.level   = 0.05,
# power       = 0.8,
n = 42,
type        = "one.sample",
alternative = "one.sided")
t.test(imc$imc ~ imc$Sex,
alternative = "less",
mu          = 0,
var.equal   = TRUE,
conf.level  = 0.95)
# p-value = 0.0003175 -> rejeitamos H0, ou seja, o IMC das populações é diferente.
# H1: mu_m < mu_h
# Resulto do hipotese < 0.05 -> podemos rejeitar H0
power.t.test(delta       = mean(imc$imc)*0.1,
sd          = sd(imc$imc),
sig.level   = 0.05,
# power       = 0.8,
n = length(imc$imc),
type        = "two.sample",
alternative = "one.sided")
# power = 0.911528
library(confintr) # package for confidence intervals
library(ggplot2)
ci_masculino = ci_mean(imc_masculino$imc, probs = c(0.05, 0.95),
type = c("t"))
ci_feminino = ci_mean(imc_feminino$imc, probs = c(0.05, 0.95),
type = c("t"))
N <- 2
for (i in 1:N) {
# generate normally distributed sample of size n
rsample <- rnorm(n, mean = 50, sd = 5)
# calculate confidence interval
ci = ci_mean(rsample, probs = c(0.025, 0.975),
type = c("t"))
mean[i] <- ci$estimate
L[i] <- ci$interval[1]
U[i] <- ci$interval[2]
}
