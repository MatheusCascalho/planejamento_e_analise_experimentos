---
title: 'Estudo de Caso 02: Avaliação e comparação do retorno médio de ações'
author: "Joao P. L. Pinto, Thales H. de O. Gonçalves, Henrique A. Barbosa, \\
date: 19 de Novembro de 2024"
output:
  html_document:
    df_print: paged
  pdf_document:
    fig_caption: true
editor_options:
  markdown:
    wrap: 72
bibliography: references.bib
csl: ieee.csl
---

```{r setup,results='hide',warning=FALSE,echo=FALSE}
# A few initial definitions just to make sure all required packages are installed. Change as needed.
# NOTE: It may echo some weird messages to the PDF on the first compile (package installation messages). Run twice and the problem will (hopefully) go away.
if (!require(ggplot2, quietly = TRUE)){
      install.packages("ggplot2")
      }
if (!require(devtools, quietly = TRUE)){
      install.packages("devtools")
      }
 if (!require(broom, quietly = TRUE)){
       devtools::install_github("dgrtwo/broom")
      }
if (!require(GGally, quietly = TRUE)){
      install.packages("GGally")
}
if (!require(ggplot2, quietly = TRUE)){
      install.packages("ggplot2")
}
if (!require(reshape2, quietly = TRUE)){
      install.packages("reshape2")
}

```

## Descrição do Problema
Em diversas situações, como no design de asas de aeronaves para maximizar a eficiência aerodinâmica \cite[della2019application] ou no treinamento de robôs para executar tarefas específicas \cite[grefenstette1994evolutionary], é necessário minimizar (ou maximizar) uma função de custo de interesse. Entretanto, quando não é possível encontrar uma solução analiticamente para seu ponto de mínimo (máximo), recorre-se a métodos heurísticos de otimização. Entre esses métodos destacam-se os algoritmos evolucionários \cite[holland1992adaptation], que simulam processos naturais de evolução, utilizando populações de possíveis soluções, inicialmente geradas de forma aleatória, para evoluir gradativamente em direção a respostas que melhor atendam ao problema em questão.

Um dos algoritmos evolucionários mais comuns e amplamente utilizados é o algoritmo de Evolução Diferencial \cite[price2006differential]. Nesse método, uma população inicial de vetores-soluções é gerada aleatoriamente, e cada indivíduo da população é avaliado com base na função de custo a ser otimizada. Durante várias iterações, ou épocas, os indivíduos passam por processos de mutação e cruzamento. A mutação introduz diversidade ao alterar características de forma aleatória, enquanto o cruzamento combina as melhores soluções, promovendo o desenvolvimento da população para um melhor resultado. Ao final do processo, o indivíduo com o melhor desempenho, ou "fit", é considerado a solução do problema.

Esse algoritmo, no entanto, apresenta múltiplos métodos de recombinação e mutação, assim como diversos hiperparâmetros, que influenciam diretamente seu funcionamento, podendo resultar em variações significativas de desempenho dependendo das configurações escolhidas. Neste trabalho, busca-se comparar o desempenho de duas configurações distintas aplicadas a dois algoritmos de Evolução Diferencial, avaliando a qualidade das soluções encontradas de forma independente do número de dimensões do problema. A tabela a seguir apresenta os métodos de recombinação e cruzamento utilizados em cada configuração do algoritmo, assim como seus respectivos hiperparâmetros.

\[
\begin{table}[]
\begin{tabular}{ccc}
Configuração & Método de Recombinação                                                                                 & Método de Mutação                                                          \\
1            & Blend Alpha Beta Recombination for DE \cite[herrera2003taxonomy] com $\alpha=0$ e $\beta=0$                                 & Em indivíduos aleatórios, com fator de escala do vetor de diferenças $f=4$ \\
2            & Recombinação Exponencial \cite[price2006differential] com probabilidade de cada ponto do vetor ser um ponto de corte $cr=0,6$ & Nos melhores indivíduos, com fator de escala do vetor de diferenças $f=2$ 
\end{tabular}
\end{table}
\]

A função de custo que deseja-se minimizar no contexto desse trabalho é a função Rosembrock para os limites $-5\le x_i \le 10$, $i=1,...,dim$ para um problema de $dim \in [2,150]$ dimensões. O tamanho da população e o número máximo de iterações do algoritmo são dependentes de $dim$, sendo esses valores $5*dim$ e $100*dim$, respectivamente. Os parâmetros experimentais dados para este estudo são:

- Mínima diferença de importância prática (padronizada): $d^*=0.5$
- Significância desejada: $\alpha=0.05$
- Potência mínima desejada: $1-\beta=0.8$

# Design dos Experimentos

Conforme descrito na seção anterior, este estudo tem como objetivo comparar o desempenho de duas configurações distintas do algoritmo de evolução diferencial no contexto de minimização da função Rosenbrock, considerando problemas com dimensões variando de 2 a 150. Para isso, busca-se:

- Verificar se existe uma diferença estatisticamente significativa no desempenho médio entre as duas configurações avaliadas; e
- Identificar qual das configurações apresenta o melhor desempenho, caso uma diferença seja constatada.

A hipótese nula estabelecida neste estudo é que os dois níveis comparados não apresentam diferenças significativas na média de seus desempenhos. Essa hipótese será rejeitada caso seja identificada alguma diferença estatisticamente significativa. No entanto, o desempenho dos algoritmos varia em função da dimensão do problema, um efeito indesejado para a comparação dos níveis. Essa variabilidade dificulta assumir que as condições experimentais sejam homogêneas, tornando inadequado o uso do teste ANOVA simples para verificar diferenças na média entre os níveis comparados.

Para isolar o efeito da dimensão do problema e tornar o experimento mais robusto e generalizável, emprega-se uma estratégia de blocagem com base no número de dimensões do problema. Nesse contexto, cada bloco corresponde a uma dimensão dentro do intervalo [2,150]. Formalmente, o modelo estatístico é definido como:

$$y_{ij}=\mu+\tau_i+\beta_j+\epsilon_{ij}\begin{cases}i=1,...,a &\\j=1,...,b\end{cases}$$
onde $y_{ij}$ é uma observação da amostra, $\mu$ é a média da amostra, $\tau_i$ o tamanho do efeito devido aos níveis, $\beta_j$ o efeito dos blocos, $\epsilon_{ij}$ o resíduo, e $a$ e $b$ o número de níveis e o número de blocos, respectivamente. No teste, o interesse está exclusivamente no fator experimental referente aos níveis, de modo que a hipótese é formulada da seguinte forma:

$$\begin{cases} H_0: \tau_{i} = 0, \forall i=1,...,a&\\H_1: \exists \tau_{i}\neq0\end{cases}$$

Para isso, é necessário determinar o número de dimensões a serem blocadas e a quantidade de amostras por blocos para se obter os parâmetros experimentais desejados, especificados na seção anterior.

# Quantidade de Dimensões

Apesar de existirem 148 grupos presentes no problema, considerando cada grupo como uma dimensão de resolução do algoritmo, não há uma necessidade efetiva de serem testados todos os grupos de variações. Para isso, podemos definir o poder do teste, assim como o número de grupos presentes no experimento, de forma a descobrir o número de instâncias necessárias.

No caso, temos que o número de grupos condiz com a quantidade de configurações do algoritmo, ou seja, duas. Além disto, seguindo o padrão expresso na literatura, temos que $\beta = 0.8$. O tamanho de efeito mínimo relevante foi definido como 0.5, uma proposta baseada no decaimento lento da função de Rosenbrock, conseguindo detectar dificuldades de caminhar em bacias de atração com gradientes pouco significativos.

O código utilizado foi baseado na biblioteca CAISEr, tal como apresentado em [@campello2019sample] e [@campelo2020sample].

## ALTERAR O CÓDIGO ABAIXO DE FORMA A EXTRUTURAR NO CONTEXTO GERAL
n_blocos = calc_instances(2, 0.5, power=0.8)


# Definição de quantidade de amostras
O planejamento da quantidade de amostras de resultado para cada dimensão é um passo importante para alcançar melhores
resultados na análise de experimentos, uma vez que com uma quantidade insuficiente de amostras corremos o risco de observar o efeito da variação das amostras se sobrepondo a variação das dimensões e das configuraçãoes dos algoritmos. Conforme proposto por [@campelo2019sample] implementamos um algoritmo iterativo para definir o tamanho de amostras necessária para cada dimensão do problema. O processo se deu da seguinte forma:

* Calculamos a quantidade de dimensões necessárias ($n_{blocos}$) para que o teste tenha poder estatístico de 80%
* Selecionamos a quantidade $n_{blocos}$ de dimensões igualmente espaçadas entre sí partindo de 2 a 150 dimensões.

Depois de definir as dimensões, partimos para a definição da quantidade de amostras por dimensão:
* Definimos o desvio padrão máximo desejado ($se*$): 
  * selecionamos 10 dimensões aleatórias;
  * executamos, para cada dimensão de teste e para cada configuração, 10 repetições do algoritmo ExpDE e armazenamos os resultados. 
  * Calculamos o desvio padrão dos resultados e calculamos o coeficiente de variaçãod e cada dimensão ($CV = \frac{\sigma}{\mu}$) e selecionamos o desvio padrão da amostra que obteve o menor coeficiente de variação. No caso, $se*= 22838.19$
* Selecionamos 10 dimensões aleatórias e calculamos a quantidade de iterações necessária para que os resultados obtidos para essa dimensão tenham no máximo o desvio padrão especificado $se*$ especificado. A quantidade mínima definida foi de 2 iterações e a máxima de 50 iterações, considerando a inviabilidade de executar mais de 50 iterações em cada dimensão e iteração.
* Após obter a quantidade de iterações de cada dimensão, selecionamos a maior quantidade de repetições e definimos como a quantidade de todas a dimensões, com o objetivo de garantir que no pior caso ainda teremos um bom nível de confiança e poder do teste, e conseguentemente para todas as outras dimensões. A quantidade de repetições definida foi de 48 repetições por dimensão-configuração.

O algoritmo implmentado é apresentado em [@campelo2019sample] e implementado em um script R separado (EC3_expecificacao_tamanho_amostras.R)

# Análise de Variância (ANOVA) - ATUALIZAR!!!

A forma convencional de começar uma comparação entre diferentes fatores (neste caso, as configurações do algoritmo) é por meio do teste ANOVA. Este teste é construído de forma a possuir um alto poder estatístico, tirando conclusões acerca da média de um conjunto de grupos ser igual como hipótese nula. O teste ANOVA utiliza o modelo dos efeitos de cada nível (no caso, cada ação, enumerada de 1 a 5) descrito como:

$$y_{ij} = \mu + \tau_i + \epsilon_{ij}$$
Nesse modelo, a variável de resposta $y_{ij}$ é igual à média global, somado ao efeito no nível, $\tau_{i}$ e ao resíduo $\epsilon_{ij}$. Temos como premissa que os resíduos seguem uma distribuição normal padrão.

Formalmente, podemos definir o experimento da seguinte forma:

$$\begin{cases} H_0: \tau_i = 0, \forall i \in \{1,2,3,4,5\} &\\H_1: \exists \tau_i \neq 0 \end{cases}$$

## Número da Amostra

Apesar de não ser possível conseguir novos dados para a execução dos
testes, é relevante confirmar se a quantidade de dados aqui presentes consegue
gerar o poder do teste esperado para nosso experimentos. Vale notar que a relevância do fator $\delta$ foi tomado como o desvio padrão dos valores, sendo o fator de relevância mais natural considerando o problema em questão.

Valores de $\alpha$ e $\beta$ utilizados são valores padrões na literatura, sendo valores de significância estatística consideráveis. O parâmetro $a$ refere-se ao número de grupos em questão, ou seja, 5 conjuntos de ações.

No contexto deste estudo, assume-se que apenas dois grupos apresentam desvios em relação à média global, enquanto os demais têm valores nulos de $\tau$. Essa abordagem reflete uma situação onde as diferenças significativas estão concentradas em apenas dois níveis.

O vetor $\tau$ foi construído de forma a representar essa suposição, com dois valores simetricamente opostos ($-\delta / 2$ e $\delta / 2$), enquanto os demais níveis são definidos como 0. A variância entre os grupos é então calculada com base nesse vetor, sendo um parâmetro fundamental para estimar o número de amostras necessárias para alcançar o poder estatístico desejado.

O código que segue traduz essa abordagem:

```{r loaddata3}
a       <- 5
alpha   <- 0.05
sigma   <- sd(rentabilidade_classificada$Valor)
delta   <- sd(rentabilidade_classificada$Valor)
beta    <- 0.2

# Case 1: two levels symmetrically biased about the grand mean
tau <- c(-delta / 2, 
         delta / 2, 
         rep(0, a - 2)) # define tau vector
vartau <- var(tau)  # variance between groups
power.anova.test(groups      = 5, 
                 between.var = vartau, 
                 within.var  = sigma ^ 2, 
                 sig.level   = alpha, 
                 power       = 1 - beta)$n

```

O valor de n presente no teste é inferior ao número de dados que possuímos para cada
grupo, com isso podemos assegurar um poder estatístico de 80% de não cometer erros do tipo II (Falso negativo).

## Teste ANOVA - ATUALIZAR!!!

Podemos realizar o teste utilizando pacotes próprios do R da seguinte forma:

```{r loaddata4}
my.model <- aov(Valor ~ Ação, 
                data = rentabilidade_classificada)
summary.aov(my.model)
```

O P valor resultante é extremamente baixo e abaixo do $\alpha$ definido, ou seja, podemos rejeitar a hipótese nula e concluir que de fato existem ações melhores que outras.

## Premissas do Teste

Dotados dos resíduos do teste, podemos conferir as premissas específicas do próprio teste. Inicialmente, verificamos se os resíduos seguem de fato uma normal padrão

```{r loaddata5}
# Check normality
shapiro.test(model$residuals)

```

```{r plotnormaldata}
plot(ecdf(model$residuals))
dados_test <- rnorm(100)
plot(ecdf(dados_test))
```

```{r loaddata6}
qqnorm(model$residuals)
qqline(model$residuals)
```

Podemos concluir que os resíduos de fato seguem suficientemente bem uma distribuição normal padrão, com um certo comportamento divergente nas caudas. Por fim, precisamos checar a igualdade de variâncias entre cada um dos fatores, ou seja, sua homoscedasticidade.

```{r loaddata7}
# Check homoscedasticity
fligner.test(novo_df$Resultado ~ novo_df$Configuração, 
             data = novo_df)
```
Novamente podemos confirmar a premissa do teste, sendo que o ANOVA com blocos se apresenta realmente como um teste confiável para este problema.

# Comparação Entre os Níveis

Após a realização do teste aleatorizado com blocos, e a rejeição de $H_0$, conclui-se que os níveis são significativamente diferentes entre si, independentemente do número de dimensões do problema. Isso indica que uma configuração de algoritmo apresenta desempenho superior ao outro.

Para um experimento com apenas dois níveis, o ideal é executar um teste t pareado. No entanto, como o problema em questão é um caso particular de uma comparação múltipla com apenas dois níveis, para identificar qual configuração oferece o melhor desempenho, decidiu-se por aplicar um teste post-hoc de Dunnett de todos os grupos contra um. Esse teste, na prática, equivale a um teste t quando se trata de apenas dois níveis. Por fim, o intervalo de confiança da diferença entre os níveis é exibido para facilitar a interpretação dos resultados.

```{r Comparison}

# Situation: all vs. one
library(multcomp)
## comparação da configuraçao #######
duntest     <- glht(model,
                    linfct = mcp(Configuração = "Dunnett"))

summary(duntest)

duntestCI   <- confint(duntest)

par(mar = c(5, 8, 4, 2), las = 1)
plot(duntestCI,
     xlab = "Mean difference")

## comparação da configuração #######
duntest     <- glht(model2,
                    linfct = mcp(Dimensao = "Dunnett"))

summary(duntest)

duntestCI   <- confint(duntest)

par(mar = c(5, 8, 4, 2), las = 1)
plot(duntestCI,
     xlab = "Mean difference")
```

É claramente perceptível que a diferença média de desempenho entre as configurações 2 e 1 é negativa em todo o intervalo de confiança, indicando que a configuração 2 sobressai em relação à configuração 1. Com base nisso, a configuração 2 foi selecionada como a de melhor desempenho.


# Discussões e Conclusões - ATUALIZAR!!!

O estudo de caso apresentou uma análise detalhada para a comparação do retorno médio de cinco ações utilizando ferramentas estatísticas, como o teste ANOVA e o teste de Diferença Significativa Honesta (HSD) de Tukey. Através da análise exploratória, constatamos variações nos retornos das ações, reforçando a necessidade de uma avaliação estatística formal para identificar diferenças significativas.

Os resultados do teste ANOVA indicaram que há diferenças estatisticamente significativas entre os grupos analisados. Subsequentemente, o teste de Tukey identificou que a ação 5 se destacou em relação às demais, apresentando o maior valor mínimo e resultados positivos consistentes. No entanto, ao compará-la diretamente com a ação 1, o intervalo de confiança incluiu valores negativos, impossibilitando afirmar com 95% de confiança que a ação 5 é significativamente superior à ação 1.

O número de amostras utilizado (35 por grupo) foi avaliado como adequado para garantir a validade estatística dos testes, superando o valor mínimo necessário de 17 amostras por grupo. Isso reforça a robustez dos resultados obtidos e a confiabilidade das conclusões.

Embora os resultados sejam consistentes dentro das premissas assumidas, o estudo apresenta limitações, como a suposição de homoscedasticidade entre os grupos e a ausência de dados adicionais para avaliação de outros fatores que podem influenciar os retornos das ações. Estudos futuros poderiam explorar a inclusão de variáveis macroeconômicas, como taxa de juros ou volatilidade do mercado, para enriquecer a análise e refinar as conclusões.

Em resumo, a metodologia empregada demonstrou ser eficaz na identificação de diferenças entre as ações analisadas, destacando a ação 5 como a mais promissora dentro do conjunto avaliado. Essa abordagem pode ser replicada em outros contextos de seleção de ativos, contribuindo para decisões de investimento mais embasadas e estratégicas.

# Bibliografia

