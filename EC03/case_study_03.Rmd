---
title: 'Estudo de Caso 02: Avaliação e comparação do retorno médio de ações'
author: "Joao P. L. Pinto, Thales H. de O. Gonçalves, Henrique A. Barbosa, \\
date: 19 de Novembro de 2024"
output:
  html_document:
    df_print: paged
  pdf_document:
    fig_caption: true
editor_options:
  markdown:
    wrap: 72
bibliography: references.bib
csl: ieee.csl
---

```{r setup,results='hide',warning=FALSE,echo=FALSE}
# A few initial definitions just to make sure all required packages are installed. Change as needed.
# NOTE: It may echo some weird messages to the PDF on the first compile (package installation messages). Run twice and the problem will (hopefully) go away.
if (!require(ggplot2, quietly = TRUE)){
      install.packages("ggplot2")
      }
if (!require(devtools, quietly = TRUE)){
      install.packages("devtools")
      }
 if (!require(broom, quietly = TRUE)){
       devtools::install_github("dgrtwo/broom")
      }
if (!require(GGally, quietly = TRUE)){
      install.packages("GGally")
}
if (!require(ggplot2, quietly = TRUE)){
      install.packages("ggplot2")
}
if (!require(reshape2, quietly = TRUE)){
      install.packages("reshape2")
}

```

## Descrição do Problema
Em diversas situações, como no design de asas de aeronaves para maximizar a eficiência aerodinâmica \cite[della2019application] ou no treinamento de robôs para executar tarefas específicas \cite[grefenstette1994evolutionary], é necessário minimizar (ou maximizar) uma função de custo. Entretanto, quando não é possível encontrar uma solução analiticamente para seu ponto de mínimo (máximo), recorre-se a métodos heurísticos de otimização. Entre esses métodos destacam-se os algoritmos evolucionários \cite[holland1992adaptation], que simulam processos naturais de evolução, utilizando populações de possíveis soluções, inicialmente geradas de forma aleatória, para evoluir gradativamente em direção a respostas que melhor atendam ao problema em questão.

Um dos algoritmos evolucionários mais comuns e amplamente utilizados é o algoritmo de Evolução Diferencial \cite[price2006differential]. Nesse método, uma população inicial de vetores-soluções é gerada aleatoriamente, e cada indivíduo da população é avaliado com base na função de custo a ser otimizada. Durante várias iterações, ou épocas, os indivíduos passam por processos de mutação e cruzamento. A mutação introduz diversidade ao alterar características de forma aleatória, enquanto o cruzamento combina as melhores soluções, promovendo o desenvolvimento da população para um melhor resultado. Ao final do processo, o indivíduo com o melhor desempenho, ou "fit", é considerado a solução do problema.

Esse algoritmo, no entanto, apresenta múltiplos métodos de recombinação e mutação, assim como diversos hiperparâmetros, que influenciam diretamente seu funcionamento, podendo resultar em variações significativas de desempenho dependendo das configurações escolhidas. Neste trabalho, busca-se comparar o desempenho de duas configurações distintas aplicadas a dois algoritmos de Evolução Diferencial, avaliando a qualidade das soluções encontradas de forma independente do número de dimensões do problema. A tabela a seguir apresenta os métodos de recombinação e cruzamento utilizados em cada configuração, assim como seus respectivos hiperparâmetros.

\[
\begin{table}[]
\begin{tabular}{ccc}
Configuração & Método de Recombinação                                                                                 & Método de Mutação                                                          \\
1            & Blend Alpha Beta Recombination for DE \cite[herrera2003taxonomy] com $\alpha=0$ e $\beta=0$                                 & Em indivíduos aleatórios, com fator de escala do vetor de diferenças $f=4$ \\
2            & Recombinação Exponencial \cite[price2006differential] com probabilidade de cada ponto do vetor ser um ponto de corte $cr=0,6$ & Nos melhores indivíduos, com fator de escala do vetor de diferenças $f=2$ 
\end{tabular}
\end{table}
\]

# Análise Exploratória e Tratamento dos Dados - ATUALIZAR!!!

Inicialmente, é necessário realizar uma transformação da base de dados fornecida
para este estudo de caso. Dado que nossa base de dados contém os preços de fechamento das ações para cada período, precisamos transformar estes dados de forma a conseguir analisar o ganho mensal da ação. Para isto, os seguintes pressupostos foram assumidos:

* Considere que o preço de abertura de um dado mês é idêntico ao preço de fechamento da mesma ação no mês anterior.
* Considere que as ações podem ser adquiridas de forma fracionária, se necessário, i.e., o montante financeiro será investido por completo em uma única ação.

A partir destes pressupostos, transformamos nossa base de dados através da seguinte fórmula:

$$Var_i = \frac{Preço_i - Preço_{i-1}}{Preço_{i-1}}$$

Podemos realizar isto utilizando o seguinte código:

```{r loaddata}
file_path <- file.path(getwd(), "DadosAcoesGrupoG.csv")
dados <- read.csv(file_path, header = FALSE)

# Renomear as colunas
colnames(dados) <- c("1", "2", "3", "4", "5")

# Criar um novo data.frame para rentabilidades
rentabilidade <- data.frame(matrix(NA, nrow = nrow(dados), ncol = ncol(dados)))
colnames(rentabilidade) <- paste0("", colnames(dados))

# Calcular a rentabilidade para cada coluna
for (i in 1:ncol(dados)) {
  # Cálculo da rentabilidade: (valor atual - valor anterior) / valor anterior
  rentabilidade[1:(nrow(dados) - 1), i] <- (dados[1:(nrow(dados) - 1), i] - dados[2:nrow(dados), i]) / dados[2:nrow(dados), i]
}
```

É útil realizar uma análise exploratória nas distribuições de rendimento,
de forma a compreendermos qual a melhor forma de se realizar os experimentos
e quais hipóteses podemos buscar:

```{r loaddata2}
library(ggplot2)
library(reshape2)

# Transformar o data frame em formato longo para usar com ggplot
# rentabilidade
rentabilidade <- na.omit(rentabilidade)
rentabilidade_classificada <- melt(rentabilidade*100, variable.name = "Ação", value.name = "Valor")

rentabilidade_classificada$Ação <- as.factor(rentabilidade_classificada$Ação)

# Plotar histogramas para cada coluna
ggplot(rentabilidade_classificada, aes(x = Valor)) +
  geom_histogram(binwidth = 1, fill = "lightblue", color = "black") +
  facet_wrap(~Ação, scales = "free") +
  labs(title = "Histogramas das Ações", x = "Valores", y = "Frequência") +
  theme_minimal()
```

Por meio destes histogramas podemos intuitivamente supor que existe de fato
uma diferença do rendimento de cada uma das ações listadas, no entanto experimentos
estatísticos devem ser realizados para poder afirmar tal hipótese.

# Quantidade de Dimensões

Apesar de existirem 148 grupos presentes no problema, considerando cada grupo como uma dimensão de resolução do algoritmo, não há uma necessidade efetiva de serem testados todos os grupos de variações. Para isso, podemos definir o poder do teste, assim como o número de grupos presentes no experimento, de forma a descobrir o número de instâncias necessárias.

No caso, temos que o número de grupos condiz com a quantidade de configurações do algoritmo, ou seja, duas. Além disto, seguindo o padrão expresso na literatura, temos que $\beta = 0.8$. O tamanho de efeito mínimo relevante foi definido como 0.5, uma proposta baseada no decaimento lento da função de Rosenbrock, conseguindo detectar dificuldades de caminhar em bacias de atração com gradientes pouco significativos.

O código utilizado foi baseado na biblioteca CAISEr, tal como apresentado em [@campello2019sample] e [@campelo2020sample].

## ALTERAR O CÓDIGO ABAIXO DE FORMA A EXTRUTURAR NO CONTEXTO GERAL
n_blocos = calc_instances(2, 0.5, power=0.8)


# Definição de quantidade de amostras
O planejamento da quantidade de amostras de resultado para cada dimensão é um passo importante para alcançar melhores
resultados na análise de experimentos, uma vez que com uma quantidade insuficiente de amostras corremos o risco de observar o efeito da variação das amostras se sobrepondo a variação das dimensões e das configuraçãoes dos algoritmos. Conforme proposto por [@campelo2019sample] implementamos um algoritmo iterativo para definir o tamanho de amostras necessária para cada dimensão do problema. O processo se deu da seguinte forma:

* Calculamos a quantidade de dimensões necessárias ($n_{blocos}$) para que o teste tenha poder estatístico de 80%
* Selecionamos a quantidade $n_{blocos}$ de dimensões igualmente espaçadas entre sí partindo de 2 a 150 dimensões.

Depois de definir as dimensões, partimos para a definição da quantidade de amostras por dimensão:
* Definimos o desvio padrão máximo desejado ($se*$): 
  * selecionamos 10 dimensões aleatórias;
  * executamos, para cada dimensão de teste e para cada configuração, 10 repetições do algoritmo ExpDE e armazenamos os resultados. 
  * Calculamos o desvio padrão dos resultados e calculamos o coeficiente de variaçãod e cada dimensão ($CV = \frac{\sigma}{\mu}$) e selecionamos o desvio padrão da amostra que obteve o menor coeficiente de variação. No caso, $se*= 22838.19$
* Selecionamos 10 dimensões aleatórias e calculamos a quantidade de iterações necessária para que os resultados obtidos para essa dimensão tenham no máximo o desvio padrão especificado $se*$ especificado. A quantidade mínima definida foi de 2 iterações e a máxima de 50 iterações, considerando a inviabilidade de executar mais de 50 iterações em cada dimensão e iteração.
* Após obter a quantidade de iterações de cada dimensão, selecionamos a maior quantidade de repetições e definimos como a quantidade de todas a dimensões, com o objetivo de garantir que no pior caso ainda teremos um bom nível de confiança e poder do teste, e conseguentemente para todas as outras dimensões. A quantidade de repetições definida foi de 48 repetições por dimensão-configuração.

O algoritmo implmentado é apresentado em [@campelo2019sample] e implementado em um script R separado (EC3_expecificacao_tamanho_amostras.R)

# Análise de Variância (ANOVA) - ATUALIZAR!!!

A forma convencional de começar uma comparação entre diferentes fatores (neste caso ações) é por meio do teste ANOVA. Este teste é construído de forma a possuir um alto poder estatístico, tirando conclusões acerca da média de um conjunto de grupos ser igual como hipótese nula. O teste ANOVA utiliza o modelo dos efeitos de cada nível (no caso, cada ação, enumerada de 1 a 5) descrito como:

$$y_{ij} = \mu + \tau_i + \epsilon_{ij}$$
Nesse modelo, a variável de resposta $y_{ij}$ é igual à média global, somado ao efeito no nível, $\tau_{i}$ e ao resíduo $\epsilon_{ij}$. Temos como premissa que os resíduos seguem uma distribuição normal padrão.

Formalmente, podemos definir o experimento da seguinte forma:

$$\begin{cases} H_0: \tau_i = 0, \forall i \in \{1,2,3,4,5\} &\\H_1: \exists \tau_i \neq 0 \end{cases}$$

## Número da Amostra

Apesar de não ser possível conseguir novos dados para a execução dos
testes, é relevante confirmar se a quantidade de dados aqui presentes consegue
gerar o poder do teste esperado para nosso experimentos. Vale notar que a relevância do fator $\delta$ foi tomado como o desvio padrão dos valores, sendo o fator de relevância mais natural considerando o problema em questão.

Valores de $\alpha$ e $\beta$ utilizados são valores padrões na literatura, sendo valores de significância estatística consideráveis. O parâmetro $a$ refere-se ao número de grupos em questão, ou seja, 5 conjuntos de ações.

No contexto deste estudo, assume-se que apenas dois grupos apresentam desvios em relação à média global, enquanto os demais têm valores nulos de $\tau$. Essa abordagem reflete uma situação onde as diferenças significativas estão concentradas em apenas dois níveis.

O vetor $\tau$ foi construído de forma a representar essa suposição, com dois valores simetricamente opostos ($-\delta / 2$ e $\delta / 2$), enquanto os demais níveis são definidos como 0. A variância entre os grupos é então calculada com base nesse vetor, sendo um parâmetro fundamental para estimar o número de amostras necessárias para alcançar o poder estatístico desejado.

O código que segue traduz essa abordagem:

```{r loaddata3}
a       <- 5
alpha   <- 0.05
sigma   <- sd(rentabilidade_classificada$Valor)
delta   <- sd(rentabilidade_classificada$Valor)
beta    <- 0.2

# Case 1: two levels symmetrically biased about the grand mean
tau <- c(-delta / 2, 
         delta / 2, 
         rep(0, a - 2)) # define tau vector
vartau <- var(tau)  # variance between groups
power.anova.test(groups      = 5, 
                 between.var = vartau, 
                 within.var  = sigma ^ 2, 
                 sig.level   = alpha, 
                 power       = 1 - beta)$n

```

O valor de n presente no teste é inferior ao número de dados que possuímos para cada
grupo, com isso podemos assegurar um poder estatístico de 80% de não cometer erros do tipo II (Falso negativo).

## Teste ANOVA

Podemos realizar o teste utilizando pacotes próprios do R da seguinte forma:

```{r loaddata4}
my.model <- aov(Valor ~ Ação, 
                data = rentabilidade_classificada)
summary.aov(my.model)
```

O P valor resultante é extremamente baixo e abaixo do $\alpha$ definido, ou seja, podemos rejeitar a hipótese nula e concluir que de fato existem ações melhores que outras.

## Premissas do Teste

Dotados dos resíduos do teste, podemos conferir as premissas específicas do próprio teste. Inicialmente, verificamos se os resíduos seguem de fato uma normal padrão

```{r loaddata5}
# Check normality
shapiro.test(my.model$residuals)

```

```{r loaddata6}
qqnorm(my.model$residuals)
qqline(my.model$residuals)
```

Podemos concluir que os resíduos de fato seguem suficientemente bem uma distribuição normal padrão. Por fim, precisamos de checar a igualdade de variâncias entre cada um dos fatores, ou seja, sua homoscedasticidade.

```{r loaddata7}
# Check homoscedasticity
fligner.test(rentabilidade_classificada$Valor ~ rentabilidade_classificada$Ação, 
             data = rentabilidade_classificada)
```
Novamente podemos confirmar a premissa do teste, sendo que o ANOVA se apresenta realmente como um teste confiável para este problema.

# Comparações Múltiplas Entre Níveis - ATUALIZAR!!!

Após a realização do teste ANOVA e a rejeição de $H_0$, conclui-se que pelo menos um dos níveis é significativamente diferente dos demais. Isso indica que uma ou mais ações apresentam resultados superiores às outras. Para identificar quais ações oferecem os melhores retornos, aplica-se o teste de Diferença Significativa Honesta (Honest Significant Difference, HSD) de Tukey, que realiza comparações entre todos os pares de níveis. Esse teste é escolhido em vez de um teste de um contra todos, pois, neste caso, não há um padrão específico a ser usado como referência. Por fim, os intervalos de confiança das diferenças entre os níveis são exibidos para facilitar a interpretação dos resultados.

```{r Multiple comparisons}

# Situation 1: all vs. all
library(multcomp)
# rentabilidade_classificada.Ação <- rentabilidade_classificada$Ação

m <- mcp(Ação="Tukey")
mc1    <- glht(my.model, linfct=m)
mc1_CI <- confint(mc1, level = 0.95)
plot(mc1_CI, 
     xlab       = "Rentabilidade da ação",
     sub        = "- Dados da ação -",
     cex.axis   = 1.2,
     cex        = 2)
```

É perceptível que os intervalos mais positivos são resultados das diferenças entre a ação 5 e as demais, indicando que ela se sobressai em relação às outras. No entanto, ao compará-la com a ação 1, parte do intervalo de confiança inclui valores negativos, impossibilitando concluir, com 95% de confiança, que a ação 5 é mais vantajosa que a ação 1. Observando o boxplot abaixo, percebe-se que a ação 5 apresenta o maior valor mínimo entre as duas. Com base nesse critério, a ação 5 foi escolhida como a mais benéfica.

```{r boxplot}
boxplot(rentabilidade,
        main = "Rentabilidade de cada Ação",
        xlab = "Ação",
        ylab = "Rentabilidade",
        col = rainbow(5))
```

Para verificar se o número de amostras utilizado é adequado para realizar o teste de comparação, foi conduzido um teste t considerando um nível de significância ($\alpha$) de 0,05, um poder estatístico de 0,8 e uma diferença mínima detectável ($\delta$) correspondente a um desvio padrão dos dados das ações, o que pode ser tomado frente à homoscedasticidade dos grupos.

```{r power t test}
sd<-sd(rentabilidade_classificada$Valor)

power.t.test(power = 0.8,
             delta = sd,
             sd = sd,
             sig.level = 0.05,
             type = "two.sample",
             alternative = "two.sided")
```

O resultado indica que o número mínimo de amostras necessário para os parâmetros especificados é 17. Como foram utilizadas 35 amostras, o requisito é plenamente atendido, garantindo a validade dos testes realizados.


# Discussões e Conclusões - ATUALIZAR!!!

O estudo de caso apresentou uma análise detalhada para a comparação do retorno médio de cinco ações utilizando ferramentas estatísticas, como o teste ANOVA e o teste de Diferença Significativa Honesta (HSD) de Tukey. Através da análise exploratória, constatamos variações nos retornos das ações, reforçando a necessidade de uma avaliação estatística formal para identificar diferenças significativas.

Os resultados do teste ANOVA indicaram que há diferenças estatisticamente significativas entre os grupos analisados. Subsequentemente, o teste de Tukey identificou que a ação 5 se destacou em relação às demais, apresentando o maior valor mínimo e resultados positivos consistentes. No entanto, ao compará-la diretamente com a ação 1, o intervalo de confiança incluiu valores negativos, impossibilitando afirmar com 95% de confiança que a ação 5 é significativamente superior à ação 1.

O número de amostras utilizado (35 por grupo) foi avaliado como adequado para garantir a validade estatística dos testes, superando o valor mínimo necessário de 17 amostras por grupo. Isso reforça a robustez dos resultados obtidos e a confiabilidade das conclusões.

Embora os resultados sejam consistentes dentro das premissas assumidas, o estudo apresenta limitações, como a suposição de homoscedasticidade entre os grupos e a ausência de dados adicionais para avaliação de outros fatores que podem influenciar os retornos das ações. Estudos futuros poderiam explorar a inclusão de variáveis macroeconômicas, como taxa de juros ou volatilidade do mercado, para enriquecer a análise e refinar as conclusões.

Em resumo, a metodologia empregada demonstrou ser eficaz na identificação de diferenças entre as ações analisadas, destacando a ação 5 como a mais promissora dentro do conjunto avaliado. Essa abordagem pode ser replicada em outros contextos de seleção de ativos, contribuindo para decisões de investimento mais embasadas e estratégicas.

# Bibliografia

